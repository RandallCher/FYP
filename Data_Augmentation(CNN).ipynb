{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cpu\n",
      "CUDA available: False\n",
      "No CUDA devices found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import nn \n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current CUDA device index (if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current CUDA device index:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"No CUDA devices found.\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with the correct path\n",
    "\n",
    "# Data from HWLab\n",
    "# file_path = './Data/25-02-10/cleaned_df.csv'\n",
    "# Data from SWlab\n",
    "file_path = './Data/25-02-04/combined_data.csv'\n",
    "\n",
    "model_path = './models/CNN/'\n",
    "cleaned_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tx_0 RSSI</th>\n",
       "      <th>Tx_1 RSSI</th>\n",
       "      <th>Tx_2 RSSI</th>\n",
       "      <th>Tx_3 RSSI</th>\n",
       "      <th>Tx_4 RSSI</th>\n",
       "      <th>Tx_5 RSSI</th>\n",
       "      <th>Tx_6 RSSI</th>\n",
       "      <th>Tx_7 RSSI</th>\n",
       "      <th>X_Coord</th>\n",
       "      <th>Y_Coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-54</td>\n",
       "      <td>-77</td>\n",
       "      <td>-74</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>-71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-54</td>\n",
       "      <td>-77</td>\n",
       "      <td>127</td>\n",
       "      <td>-81</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>-81</td>\n",
       "      <td>-71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-54</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>-71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-54</td>\n",
       "      <td>-77</td>\n",
       "      <td>-74</td>\n",
       "      <td>-82</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>-82</td>\n",
       "      <td>-70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-54</td>\n",
       "      <td>-77</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>-78</td>\n",
       "      <td>-80</td>\n",
       "      <td>-70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>-70</td>\n",
       "      <td>-69</td>\n",
       "      <td>-80</td>\n",
       "      <td>-65</td>\n",
       "      <td>-79</td>\n",
       "      <td>127</td>\n",
       "      <td>-73</td>\n",
       "      <td>-62</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>-70</td>\n",
       "      <td>-70</td>\n",
       "      <td>-84</td>\n",
       "      <td>-65</td>\n",
       "      <td>-79</td>\n",
       "      <td>-84</td>\n",
       "      <td>-74</td>\n",
       "      <td>-61</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>-70</td>\n",
       "      <td>-69</td>\n",
       "      <td>-80</td>\n",
       "      <td>-64</td>\n",
       "      <td>-80</td>\n",
       "      <td>127</td>\n",
       "      <td>-76</td>\n",
       "      <td>-61</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>-70</td>\n",
       "      <td>-70</td>\n",
       "      <td>-82</td>\n",
       "      <td>-67</td>\n",
       "      <td>-83</td>\n",
       "      <td>-84</td>\n",
       "      <td>-79</td>\n",
       "      <td>-61</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>-70</td>\n",
       "      <td>-72</td>\n",
       "      <td>-80</td>\n",
       "      <td>-69</td>\n",
       "      <td>-82</td>\n",
       "      <td>127</td>\n",
       "      <td>-78</td>\n",
       "      <td>-61</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7394 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tx_0 RSSI  Tx_1 RSSI  Tx_2 RSSI  Tx_3 RSSI  Tx_4 RSSI  Tx_5 RSSI  \\\n",
       "0           -54        -77        -74        127        127        -78   \n",
       "1           -54        -77        127        -81        127        127   \n",
       "2           -54        127        127        127        127        127   \n",
       "3           -54        -77        -74        -82        127        127   \n",
       "4           -54        -77        127        127        127        -78   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "7389        -70        -69        -80        -65        -79        127   \n",
       "7390        -70        -70        -84        -65        -79        -84   \n",
       "7391        -70        -69        -80        -64        -80        127   \n",
       "7392        -70        -70        -82        -67        -83        -84   \n",
       "7393        -70        -72        -80        -69        -82        127   \n",
       "\n",
       "      Tx_6 RSSI  Tx_7 RSSI  X_Coord  Y_Coord  \n",
       "0           127        -71        0        0  \n",
       "1           -81        -71        0        0  \n",
       "2           127        -71        0        0  \n",
       "3           -82        -70        0        0  \n",
       "4           -80        -70        0        0  \n",
       "...         ...        ...      ...      ...  \n",
       "7389        -73        -62        4        3  \n",
       "7390        -74        -61        4        3  \n",
       "7391        -76        -61        4        3  \n",
       "7392        -79        -61        4        3  \n",
       "7393        -78        -61        4        3  \n",
       "\n",
       "[7394 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import preprocess_dataset\n",
    "\n",
    "# X = cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "# X = cleaned_df[['Tx_0 RSSI_Avg', 'Tx_1 RSSI_Avg', 'Tx_2 RSSI_Avg', 'Tx_3 RSSI_Avg', 'Tx_4 RSSI_Avg', 'Tx_5 RSSI_Avg', 'Tx_6 RSSI_Avg', 'Tx_7 RSSI_Avg']]\n",
    "X = cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "Y = cleaned_df[['X_Coord', 'Y_Coord']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data = {}\n",
    "\n",
    "# Collect RSSI values per (X_Coord, Y_Coord)\n",
    "for index, row in cleaned_df.iterrows():\n",
    "    x, y = int(row['X_Coord']), int(row['Y_Coord'])\n",
    "    \n",
    "    # Initialize empty list for this location if not already present\n",
    "    if (x, y) not in grid_data:\n",
    "        grid_data[(x, y)] = []\n",
    "    \n",
    "    # Append RSSI values (Tx_0 to Tx_7)\n",
    "    grid_data[(x, y)].append(row[X.columns].values)\n",
    "\n",
    "# Define parameters\n",
    "num_tx = 8      # Number of transmitters\n",
    "seq_length = 8  # Sequence length (8 samples per training instance)\n",
    "stride = 1      # Sliding window step (adjustable)\n",
    "\n",
    "\n",
    "training_samples = []\n",
    "\n",
    "# For sampling in order\n",
    "for (x, y), rssi_values in grid_data.items():\n",
    "    rssi_array = np.array(rssi_values) \n",
    "    \n",
    "    if rssi_array.shape[0] < seq_length:\n",
    "        continue \n",
    "\n",
    "    num_samples = rssi_array.shape[0]\n",
    "\n",
    "    for start in range(0, num_samples - seq_length + 1, stride):\n",
    "        window = rssi_array[start:start + seq_length].T  \n",
    "        training_samples.append((window, (x, y)))\n",
    "\n",
    "with open('./Data/CNN_Data/CNN_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(training_samples, f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating augmented data\n",
    "\n",
    "# grid_data = {}\n",
    "\n",
    "# # Collect RSSI values per (X_Coord, Y_Coord)\n",
    "# for index, row in cleaned_df.iterrows():\n",
    "#     x, y = int(row['X_Coord']), int(row['Y_Coord'])\n",
    "    \n",
    "#     if (x, y) not in grid_data:\n",
    "#         grid_data[(x, y)] = []\n",
    "    \n",
    "#     # Append RSSI values (Tx_0 to Tx_7)\n",
    "#     grid_data[(x, y)].append(row[X.columns].values)\n",
    "\n",
    "# # Define parameters\n",
    "# num_tx = 8      # Number of transmitters\n",
    "# seq_length = 8  # Sequence length (8 samples per training instance)\n",
    "# stride = 1      # Sliding window step (adjustable)\n",
    "\n",
    "# training_samples = []\n",
    "# augmented_samples = []\n",
    "\n",
    "# # Convert grid_data keys to a list for easy access\n",
    "# locations = list(grid_data.keys())\n",
    "\n",
    "# # For sampling in order\n",
    "# for (x, y), rssi_values in grid_data.items():\n",
    "#     rssi_array = np.array(rssi_values) \n",
    "    \n",
    "#     if rssi_array.shape[0] < seq_length:\n",
    "#         continue \n",
    "\n",
    "#     num_samples = rssi_array.shape[0]\n",
    "\n",
    "#     for start in range(0, num_samples - seq_length + 1, stride):\n",
    "#         window = rssi_array[start:start + seq_length].T  \n",
    "#         training_samples.append((window, (x, y)))\n",
    "\n",
    "#         # Augment data by replacing two rows with random rows from another location\n",
    "#         aug_window = window.copy()\n",
    "#         rand_locs = random.sample(locations, 2)  # Select 2 random locations\n",
    "#         for rand_loc in rand_locs:\n",
    "#             if rand_loc in grid_data and len(grid_data[rand_loc]) > 0:\n",
    "#                 rand_idx = random.randint(0, len(grid_data[rand_loc]) - 1)\n",
    "#                 aug_window[random.randint(0, num_tx - 1)] = np.array(grid_data[rand_loc][rand_idx])\n",
    "\n",
    "#         augmented_samples.append((aug_window, (x, y)))\n",
    "\n",
    "# # Combine original and augmented data\n",
    "# final_samples = training_samples + augmented_samples\n",
    "\n",
    "# with open('./Data/CNN_Data/CNN_train_data_2fold.pkl', 'wb') as f:\n",
    "#     pickle.dump(final_samples, f)\n",
    "\n",
    "# print(f\"Original samples: {len(training_samples)}\")\n",
    "# print(f\"Augmented samples: {len(augmented_samples)}\")\n",
    "# print(f\"Total dataset size: {len(final_samples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated training data shape: (6946, 8, 8)\n",
      "Generated labels shape: (6946, 2)\n"
     ]
    }
   ],
   "source": [
    "if training_samples:\n",
    "    X_Sequence = np.array([sample[0] for sample in training_samples])  # Shape: (num_samples, Tx, 8)\n",
    "    y_Sequence = np.array([sample[1] for sample in training_samples])  # Shape: (num_samples, 2) -> (X_Coord, Y_Coord)\n",
    "else:\n",
    "    X_Sequence = np.array([])\n",
    "    y_Sequence = np.array([])\n",
    "\n",
    "print(\"Generated training data shape:\", X_Sequence.shape)\n",
    "print(\"Generated labels shape:\", y_Sequence.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
