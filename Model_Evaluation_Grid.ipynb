{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn \n",
    "import joblib\n",
    "\n",
    "# from common_utils import MLPBuilder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "modelname = 'DNN_model_with_features_SWLab[512, 512, 256, 256]'\n",
    "modellayer = [512, 512, 256, 256]\n",
    "no_features=11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBuilder(nn.Module):\n",
    "\n",
    "    def __init__(self, no_features, layers):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        \n",
    "        # Input layer\n",
    "        layer_list.append(nn.Linear(no_features, layers[0]))\n",
    "        layer_list.append(nn.ReLU())\n",
    "        layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(layers) - 1):\n",
    "            layer_list.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            layer_list.append(nn.ReLU())\n",
    "            layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Define the MLP stack as a sequential model\n",
    "        self.mlp_stack = nn.Sequential(*layer_list)\n",
    "\n",
    "        # Output layer, 1 outputs\n",
    "        self.output_x = nn.Linear(layers[-1], 8) \n",
    "        self.output_y = nn.Linear(layers[-1], 8) \n",
    "\n",
    "\n",
    "        self._initialize_weights() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.mlp_stack(x)\n",
    "        logits_x = self.output_x(features)\n",
    "        logits_y = self.output_y(features)\n",
    "        return logits_x, logits_y\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.mlp_stack:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                # Use Kaiming initialization for ReLU activations\n",
    "                nn.init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_12104\\1835588017.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/Grid_based/'+ modelname +'.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPBuilder(\n",
       "  (mlp_stack): Sequential(\n",
       "    (0): Linear(in_features=11, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (output_x): Linear(in_features=256, out_features=8, bias=True)\n",
       "  (output_y): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPBuilder(no_features, layers=modellayer)\n",
    "model.load_state_dict(torch.load('models/Grid_based/'+ modelname +'.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_file_path = './Data/25-02-10/cleaned_df_features.csv'\n",
    "\n",
    "test_file_path = './Data/25-02-04/cleaned_df_features.csv'\n",
    "\n",
    "model_path = './models/Grid_based'\n",
    "scaler_X = joblib.load(model_path +'/scaler_X.pkl')\n",
    "# scaler_Y = joblib.load(model_path +'/scaler_Y.pkl')\n",
    "\n",
    "train_cleaned_df = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tx_0 RSSI</th>\n",
       "      <th>Tx_1 RSSI</th>\n",
       "      <th>Tx_2 RSSI</th>\n",
       "      <th>Tx_3 RSSI</th>\n",
       "      <th>Tx_4 RSSI</th>\n",
       "      <th>Tx_5 RSSI</th>\n",
       "      <th>Tx_6 RSSI</th>\n",
       "      <th>Tx_7 RSSI</th>\n",
       "      <th>X_Coord</th>\n",
       "      <th>Y_Coord</th>\n",
       "      <th>RSSI_Mean</th>\n",
       "      <th>RSSI_Variance</th>\n",
       "      <th>RSSI_Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-61</td>\n",
       "      <td>-74</td>\n",
       "      <td>-79</td>\n",
       "      <td>127</td>\n",
       "      <td>-81</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>-84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.375</td>\n",
       "      <td>8892.267857</td>\n",
       "      <td>-76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-61</td>\n",
       "      <td>-73</td>\n",
       "      <td>-78</td>\n",
       "      <td>-71</td>\n",
       "      <td>127</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>10656.571429</td>\n",
       "      <td>-66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-62</td>\n",
       "      <td>-75</td>\n",
       "      <td>-78</td>\n",
       "      <td>-72</td>\n",
       "      <td>-79</td>\n",
       "      <td>127</td>\n",
       "      <td>-84</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.500</td>\n",
       "      <td>8784.285714</td>\n",
       "      <td>-73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-61</td>\n",
       "      <td>-73</td>\n",
       "      <td>-80</td>\n",
       "      <td>-71</td>\n",
       "      <td>-83</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.000</td>\n",
       "      <td>8730.571429</td>\n",
       "      <td>-72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-61</td>\n",
       "      <td>-75</td>\n",
       "      <td>-78</td>\n",
       "      <td>-71</td>\n",
       "      <td>-84</td>\n",
       "      <td>-78</td>\n",
       "      <td>-84</td>\n",
       "      <td>-86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.125</td>\n",
       "      <td>68.125000</td>\n",
       "      <td>-78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>-79</td>\n",
       "      <td>-69</td>\n",
       "      <td>-81</td>\n",
       "      <td>-74</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-78</td>\n",
       "      <td>-68</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.500</td>\n",
       "      <td>45.428571</td>\n",
       "      <td>-72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>-77</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77</td>\n",
       "      <td>-71</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-79</td>\n",
       "      <td>-67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-71.375</td>\n",
       "      <td>36.553571</td>\n",
       "      <td>-70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>-77</td>\n",
       "      <td>-69</td>\n",
       "      <td>-81</td>\n",
       "      <td>-73</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-79</td>\n",
       "      <td>-66</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.000</td>\n",
       "      <td>46.571429</td>\n",
       "      <td>-71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>-80</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-71</td>\n",
       "      <td>-61</td>\n",
       "      <td>-76</td>\n",
       "      <td>-67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-71.625</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>-71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>-77</td>\n",
       "      <td>-68</td>\n",
       "      <td>-81</td>\n",
       "      <td>-72</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-70</td>\n",
       "      <td>-68</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-70.875</td>\n",
       "      <td>36.696429</td>\n",
       "      <td>-70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tx_0 RSSI  Tx_1 RSSI  Tx_2 RSSI  Tx_3 RSSI  Tx_4 RSSI  Tx_5 RSSI  \\\n",
       "0           -61        -74        -79        127        -81        -78   \n",
       "1           -61        -73        -78        -71        127        -78   \n",
       "2           -62        -75        -78        -72        -79        127   \n",
       "3           -61        -73        -80        -71        -83        -78   \n",
       "4           -61        -75        -78        -71        -84        -78   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6395        -79        -69        -81        -74        -70        -61   \n",
       "6396        -77        -69        -77        -71        -70        -61   \n",
       "6397        -77        -69        -81        -73        -70        -61   \n",
       "6398        -80        -69        -77        -72        -71        -61   \n",
       "6399        -77        -68        -81        -72        -70        -61   \n",
       "\n",
       "      Tx_6 RSSI  Tx_7 RSSI  X_Coord  Y_Coord  RSSI_Mean  RSSI_Variance  \\\n",
       "0           127        -84        0        0    -25.375    8892.267857   \n",
       "1           127        127        0        0      2.500   10656.571429   \n",
       "2           -84        127        0        0    -24.500    8784.285714   \n",
       "3           127        127        0        0    -24.000    8730.571429   \n",
       "4           -84        -86        0        0    -77.125      68.125000   \n",
       "...         ...        ...      ...      ...        ...            ...   \n",
       "6395        -78        -68        6        0    -72.500      45.428571   \n",
       "6396        -79        -67        6        0    -71.375      36.553571   \n",
       "6397        -79        -66        6        0    -72.000      46.571429   \n",
       "6398        -76        -67        6        0    -71.625      37.125000   \n",
       "6399        -70        -68        6        0    -70.875      36.696429   \n",
       "\n",
       "      RSSI_Median  \n",
       "0           -76.0  \n",
       "1           -66.0  \n",
       "2           -73.5  \n",
       "3           -72.0  \n",
       "4           -78.0  \n",
       "...           ...  \n",
       "6395        -72.0  \n",
       "6396        -70.5  \n",
       "6397        -71.5  \n",
       "6398        -71.5  \n",
       "6399        -70.0  \n",
       "\n",
       "[6400 rows x 13 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batt_columns = [col for col in cleaned_df.columns if 'Batt' in col]\n",
    "# time_columns = [col for col in cleaned_df.columns if 'Time' in col]\n",
    "# columns_to_drop = batt_columns+time_columns\n",
    "# RSSI_columns = cleaned_df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "# #Train the model without NAN values\n",
    "# # cleaned_df = RSSI_columns.dropna()\n",
    "\n",
    "# #Convert NaN values to 0\n",
    "# cleaned_df = RSSI_columns.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_features == 8:\n",
    "    X_train = train_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "if no_features == 11:\n",
    "    X_train = train_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI', 'RSSI_Mean', 'RSSI_Variance', 'RSSI_Median']]\n",
    "\n",
    "Y_train = train_cleaned_df[['X_Coord', 'Y_Coord']]\n",
    "\n",
    "X_train_scaled = scaler_X.transform(X_train)\n",
    "\n",
    "Y_test_array = Y_train.to_numpy()\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_test_array, dtype=torch.float32)  \n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  \n",
    "    total_loss = 0.0\n",
    "    total_displacement = 0.0\n",
    "    total_samples = 0\n",
    "    criterion_x = nn.CrossEntropyLoss()\n",
    "    criterion_y = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            logits_x, logits_y = model(inputs)  \n",
    "            \n",
    "            target_x = targets[:, 0].long()\n",
    "            target_y = targets[:, 1].long()\n",
    "\n",
    "            loss_x = criterion_x(logits_x, target_x)\n",
    "            loss_y = criterion_y(logits_y, target_y)\n",
    "\n",
    "            total_loss += (loss_x.item() + loss_y.item()) * targets.size(0)\n",
    "            \n",
    "            # Compute displacement error (L2 distance)\n",
    "            pred_x = torch.argmax(logits_x, dim=1)\n",
    "            pred_y = torch.argmax(logits_y, dim=1)\n",
    "            displacement = torch.sqrt((pred_x - target_x) ** 2 + (pred_y - target_y) ** 2)\n",
    "            total_displacement += displacement.sum().item()\n",
    "            \n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_displacement = total_displacement / total_samples  # Average displacement error\n",
    "\n",
    "    return avg_loss, avg_displacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 12.045263\n",
      "Test Displacement Loss: 3.310755\n"
     ]
    }
   ],
   "source": [
    "avg_loss, displacement_loss = evaluate_model(model, train_loader)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE Loss: {avg_loss:.6f}\")\n",
    "print(f\"Test Displacement Loss: {displacement_loss:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing transfer learning in test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned_df = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_features == 8:    \n",
    "    X_test = test_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "if no_features == 11: \n",
    "    X_test = test_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI', 'RSSI_Mean', 'RSSI_Variance', 'RSSI_Median']]\n",
    "\n",
    "Y_test = test_cleaned_df[['X_Coord', 'Y_Coord']]\n",
    "\n",
    "X_test, X_val, Y_test, Y_val  = train_test_split(X_test, Y_test, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "Y_test_scaled = Y_test.to_numpy()\n",
    "Y_val_scaled = Y_val.to_numpy()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "Y_val_tensor = torch.tensor(Y_val_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 0.166119\n",
      "Test Displacement Loss: 0.117488\n"
     ]
    }
   ],
   "source": [
    "avg_loss, displacement_loss = evaluate_model(model, test_loader)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE Loss: {avg_loss:.6f}\")\n",
    "print(f\"Test Displacement Loss: {displacement_loss:.6f}\") \n",
    "before_training_loss = displacement_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_stack.0.weight False\n",
      "mlp_stack.0.bias False\n",
      "mlp_stack.3.weight False\n",
      "mlp_stack.3.bias False\n",
      "mlp_stack.6.weight False\n",
      "mlp_stack.6.bias False\n",
      "mlp_stack.9.weight False\n",
      "mlp_stack.9.bias False\n",
      "output_x.weight True\n",
      "output_x.bias True\n",
      "output_y.weight True\n",
      "output_y.bias True\n"
     ]
    }
   ],
   "source": [
    "for param in model.mlp_stack.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "# Ensure output layers are trainable\n",
    "for param in model.output_x.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.output_y.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "    \n",
    "# Define optimizer for only trainable parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.479942\n",
      "Epoch [2/100], Loss: 0.446272\n",
      "Epoch [3/100], Loss: 0.456034\n",
      "Epoch [4/100], Loss: 0.453443\n",
      "Epoch [5/100], Loss: 0.449935\n",
      "Epoch [6/100], Loss: 0.436179\n",
      "Epoch [7/100], Loss: 0.443318\n",
      "Epoch [8/100], Loss: 0.437160\n",
      "Epoch [9/100], Loss: 0.438418\n",
      "Epoch [10/100], Loss: 0.429600\n",
      "Epoch [11/100], Loss: 0.433203\n",
      "Epoch [12/100], Loss: 0.460600\n",
      "Epoch [13/100], Loss: 0.452337\n",
      "Epoch [14/100], Loss: 0.444046\n",
      "Epoch [15/100], Loss: 0.428899\n",
      "Epoch [16/100], Loss: 0.425206\n",
      "Epoch [17/100], Loss: 0.424378\n",
      "Epoch [18/100], Loss: 0.439710\n",
      "Epoch [19/100], Loss: 0.425111\n",
      "Epoch [20/100], Loss: 0.418756\n",
      "Epoch [21/100], Loss: 0.445554\n",
      "Epoch [22/100], Loss: 0.436135\n",
      "Epoch [23/100], Loss: 0.443854\n",
      "Epoch [24/100], Loss: 0.433148\n",
      "Epoch [25/100], Loss: 0.434706\n",
      "Early stopping triggered after 25 epochs.\n",
      "Transfer learning complete. Total training time: 2.84 sec\n",
      "Transfer learning complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 5  \n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        logits_x, logits_y = model(inputs)  # Forward pass\n",
    "        \n",
    "        target_x = targets[:, 0].long()  # Convert targets to integer indices\n",
    "        target_y = targets[:, 1].long()\n",
    "\n",
    "        loss_x = criterion(logits_x, target_x)\n",
    "        loss_y = criterion(logits_y, target_y)\n",
    "        \n",
    "        loss = loss_x + loss_y  # Total loss\n",
    "        \n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  \n",
    "\n",
    "        total_loss += loss.item() * targets.size(0)  \n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples  \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        epochs_no_improve = 0  # Reset counter if loss improves\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break  # Stop training if no improvement for `patience` epochs\n",
    "\n",
    "total_time = time.time() - start_time  # Calculate total training time\n",
    "print(f\"Transfer learning complete. Total training time: {total_time:.2f} sec\")\n",
    "\n",
    "print(\"Transfer learning complete.\")\n",
    "# torch.save(model.state_dict(), \"models/Regression_based/DNN_model_[256, 512, 512, 128]_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 0.792164\n",
      "Test Displacement Loss: 0.508155\n"
     ]
    }
   ],
   "source": [
    "avg_loss, displacement_loss = evaluate_model(model, val_loader)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE Loss: {avg_loss:.6f}\")\n",
    "print(f\"Test Displacement Loss: {displacement_loss:.6f}\")\n",
    "after_training_loss = displacement_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Transfer learning: 0.117488\n",
      "After Transfer learning: 0.508155\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before Transfer learning: {before_training_loss:.6f}\")\n",
    "print(f\"After Transfer learning: {after_training_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
