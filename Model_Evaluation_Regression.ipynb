{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn \n",
    "import joblib\n",
    "\n",
    "# from common_utils import MLPBuilder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "modelname = 'DNN_model_with_features_[256, 512, 512, 64]'\n",
    "modellayer = [256, 512, 512, 64]\n",
    "no_features=11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBuilder(nn.Module):\n",
    "\n",
    "    def __init__(self, no_features, layers):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        \n",
    "        # Input layer\n",
    "        layer_list.append(nn.Linear(no_features, layers[0]))\n",
    "        layer_list.append(nn.ReLU())\n",
    "        layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(layers) - 1):\n",
    "            layer_list.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            layer_list.append(nn.ReLU())\n",
    "            layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Output layer, 2 outputs\n",
    "        layer_list.append(nn.Linear(layers[-1], 2))\n",
    " \n",
    "        # Define the MLP stack as a sequential model\n",
    "        self.mlp_stack = nn.Sequential(*layer_list)\n",
    "\n",
    "        self._initialize_weights() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.mlp_stack(x)\n",
    "        return logits\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.mlp_stack:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                # Use Kaiming initialization for ReLU activations\n",
    "                nn.init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_22584\\1423733962.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/Regression_based/'+ modelname +'.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPBuilder(\n",
       "  (mlp_stack): Sequential(\n",
       "    (0): Linear(in_features=11, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we trained the model with 8 features\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPBuilder(no_features, layers=modellayer)\n",
    "model.load_state_dict(torch.load('models/Regression_based/'+ modelname +'.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_file_path = './Data/25-02-10/cleaned_df_features.csv'\n",
    "test_file_path = './Data/25-02-04/cleaned_df_features.csv'\n",
    "\n",
    "model_path = './models/Regression_based'\n",
    "scaler_X = joblib.load(model_path +'/scaler_X.pkl')\n",
    "scaler_Y = joblib.load(model_path +'/scaler_Y.pkl')\n",
    "\n",
    "train_cleaned_df = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tx_0 RSSI</th>\n",
       "      <th>Tx_1 RSSI</th>\n",
       "      <th>Tx_2 RSSI</th>\n",
       "      <th>Tx_3 RSSI</th>\n",
       "      <th>Tx_4 RSSI</th>\n",
       "      <th>Tx_5 RSSI</th>\n",
       "      <th>Tx_6 RSSI</th>\n",
       "      <th>Tx_7 RSSI</th>\n",
       "      <th>X_Coord</th>\n",
       "      <th>Y_Coord</th>\n",
       "      <th>RSSI_Mean</th>\n",
       "      <th>RSSI_Variance</th>\n",
       "      <th>RSSI_Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-61</td>\n",
       "      <td>-74</td>\n",
       "      <td>-79</td>\n",
       "      <td>127</td>\n",
       "      <td>-81</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>-84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.375</td>\n",
       "      <td>8892.267857</td>\n",
       "      <td>-76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-61</td>\n",
       "      <td>-73</td>\n",
       "      <td>-78</td>\n",
       "      <td>-71</td>\n",
       "      <td>127</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>10656.571429</td>\n",
       "      <td>-66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-62</td>\n",
       "      <td>-75</td>\n",
       "      <td>-78</td>\n",
       "      <td>-72</td>\n",
       "      <td>-79</td>\n",
       "      <td>127</td>\n",
       "      <td>-84</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.500</td>\n",
       "      <td>8784.285714</td>\n",
       "      <td>-73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-61</td>\n",
       "      <td>-73</td>\n",
       "      <td>-80</td>\n",
       "      <td>-71</td>\n",
       "      <td>-83</td>\n",
       "      <td>-78</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.000</td>\n",
       "      <td>8730.571429</td>\n",
       "      <td>-72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-61</td>\n",
       "      <td>-75</td>\n",
       "      <td>-78</td>\n",
       "      <td>-71</td>\n",
       "      <td>-84</td>\n",
       "      <td>-78</td>\n",
       "      <td>-84</td>\n",
       "      <td>-86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.125</td>\n",
       "      <td>68.125000</td>\n",
       "      <td>-78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>-79</td>\n",
       "      <td>-69</td>\n",
       "      <td>-81</td>\n",
       "      <td>-74</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-78</td>\n",
       "      <td>-68</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.500</td>\n",
       "      <td>45.428571</td>\n",
       "      <td>-72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>-77</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77</td>\n",
       "      <td>-71</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-79</td>\n",
       "      <td>-67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-71.375</td>\n",
       "      <td>36.553571</td>\n",
       "      <td>-70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>-77</td>\n",
       "      <td>-69</td>\n",
       "      <td>-81</td>\n",
       "      <td>-73</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-79</td>\n",
       "      <td>-66</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.000</td>\n",
       "      <td>46.571429</td>\n",
       "      <td>-71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>-80</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-71</td>\n",
       "      <td>-61</td>\n",
       "      <td>-76</td>\n",
       "      <td>-67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-71.625</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>-71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>-77</td>\n",
       "      <td>-68</td>\n",
       "      <td>-81</td>\n",
       "      <td>-72</td>\n",
       "      <td>-70</td>\n",
       "      <td>-61</td>\n",
       "      <td>-70</td>\n",
       "      <td>-68</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-70.875</td>\n",
       "      <td>36.696429</td>\n",
       "      <td>-70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tx_0 RSSI  Tx_1 RSSI  Tx_2 RSSI  Tx_3 RSSI  Tx_4 RSSI  Tx_5 RSSI  \\\n",
       "0           -61        -74        -79        127        -81        -78   \n",
       "1           -61        -73        -78        -71        127        -78   \n",
       "2           -62        -75        -78        -72        -79        127   \n",
       "3           -61        -73        -80        -71        -83        -78   \n",
       "4           -61        -75        -78        -71        -84        -78   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6395        -79        -69        -81        -74        -70        -61   \n",
       "6396        -77        -69        -77        -71        -70        -61   \n",
       "6397        -77        -69        -81        -73        -70        -61   \n",
       "6398        -80        -69        -77        -72        -71        -61   \n",
       "6399        -77        -68        -81        -72        -70        -61   \n",
       "\n",
       "      Tx_6 RSSI  Tx_7 RSSI  X_Coord  Y_Coord  RSSI_Mean  RSSI_Variance  \\\n",
       "0           127        -84        0        0    -25.375    8892.267857   \n",
       "1           127        127        0        0      2.500   10656.571429   \n",
       "2           -84        127        0        0    -24.500    8784.285714   \n",
       "3           127        127        0        0    -24.000    8730.571429   \n",
       "4           -84        -86        0        0    -77.125      68.125000   \n",
       "...         ...        ...      ...      ...        ...            ...   \n",
       "6395        -78        -68        6        0    -72.500      45.428571   \n",
       "6396        -79        -67        6        0    -71.375      36.553571   \n",
       "6397        -79        -66        6        0    -72.000      46.571429   \n",
       "6398        -76        -67        6        0    -71.625      37.125000   \n",
       "6399        -70        -68        6        0    -70.875      36.696429   \n",
       "\n",
       "      RSSI_Median  \n",
       "0           -76.0  \n",
       "1           -66.0  \n",
       "2           -73.5  \n",
       "3           -72.0  \n",
       "4           -78.0  \n",
       "...           ...  \n",
       "6395        -72.0  \n",
       "6396        -70.5  \n",
       "6397        -71.5  \n",
       "6398        -71.5  \n",
       "6399        -70.0  \n",
       "\n",
       "[6400 rows x 13 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batt_columns = [col for col in cleaned_df.columns if 'Batt' in col]\n",
    "# time_columns = [col for col in cleaned_df.columns if 'Time' in col]\n",
    "# columns_to_drop = batt_columns+time_columns\n",
    "# RSSI_columns = cleaned_df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "#Train the model without NAN values\n",
    "# cleaned_df = RSSI_columns.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "X_train = train_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI', 'RSSI_Mean', 'RSSI_Variance', 'RSSI_Median']]\n",
    "Y_train = train_cleaned_df[['X_Coord', 'Y_Coord']]\n",
    "\n",
    "X_train_scaled = scaler_X.transform(X_train)\n",
    "Y_train_scaled = scaler_Y.transform(Y_train)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train_scaled, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    total_displacement_error = 0.0\n",
    "    total_mse_loss = 0.0\n",
    "    total_samples = 0\n",
    "    criterion = nn.MSELoss()  # MSE loss function\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move to GPU if available\n",
    "            \n",
    "            preds = model(inputs)  # Model outputs predicted X and Y coordinates\n",
    "\n",
    "            # Compute MSE loss\n",
    "            mse_loss = criterion(preds, targets)\n",
    "\n",
    "            # Compute displacement error (Euclidean distance)\n",
    "            displacement = torch.sqrt(torch.sum((preds - targets) ** 2, dim=1))\n",
    "            \n",
    "            # Accumulate total error\n",
    "            total_mse_loss += mse_loss.item() * targets.size(0)  # Weighted sum for averaging\n",
    "            total_displacement_error += displacement.sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    # Compute mean values\n",
    "    avg_loss = total_mse_loss / total_samples\n",
    "    avg_displacement_error = total_displacement_error / total_samples\n",
    "    \n",
    "    return avg_loss, avg_displacement_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 0.016331\n",
      "Test Displacement Loss: 0.129988\n"
     ]
    }
   ],
   "source": [
    "avg_loss, displacement_loss = evaluate_model(model, train_loader)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE Loss: {avg_loss:.6f}\")\n",
    "print(f\"Test Displacement Loss: {displacement_loss:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing transfer learning in test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned_df = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = test_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "X_test = test_cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI', 'RSSI_Mean', 'RSSI_Variance', 'RSSI_Median']]\n",
    "Y_test = test_cleaned_df[['X_Coord', 'Y_Coord']]\n",
    "\n",
    "X_test, X_val, Y_test, Y_val  = train_test_split(X_test, Y_test, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "Y_val_scaled = scaler_Y.transform(Y_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "Y_val_tensor = torch.tensor(Y_val_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 0.115628\n",
      "Test Displacement Loss: 0.428938\n"
     ]
    }
   ],
   "source": [
    "avg_loss, displacement_loss = evaluate_model(model, test_loader)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE Loss: {avg_loss:.6f}\")\n",
    "print(f\"Test Displacement Loss: {displacement_loss:.6f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_stack.0.weight False\n",
      "mlp_stack.0.bias False\n",
      "mlp_stack.3.weight False\n",
      "mlp_stack.3.bias False\n",
      "mlp_stack.6.weight False\n",
      "mlp_stack.6.bias False\n",
      "mlp_stack.9.weight False\n",
      "mlp_stack.9.bias False\n",
      "mlp_stack.12.weight True\n",
      "mlp_stack.12.bias True\n"
     ]
    }
   ],
   "source": [
    "for param in model.mlp_stack[:-1].parameters():  # Freeze all except last layer\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.mlp_stack[-1].in_features\n",
    "model.mlp_stack[-1] = nn.Linear(num_features, 2)\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Verify layer status\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.mlp_stack[-1].parameters(), lr=0.001, weight_decay=1e-4)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.353262\n",
      "Epoch [2/100], Loss: 0.245571\n",
      "Epoch [3/100], Loss: 0.180859\n",
      "Epoch [4/100], Loss: 0.146001\n",
      "Epoch [5/100], Loss: 0.127386\n",
      "Epoch [6/100], Loss: 0.119645\n",
      "Epoch [7/100], Loss: 0.114281\n",
      "Epoch [8/100], Loss: 0.109744\n",
      "Epoch [9/100], Loss: 0.108246\n",
      "Epoch [10/100], Loss: 0.106163\n",
      "Epoch [11/100], Loss: 0.104133\n",
      "Epoch [12/100], Loss: 0.103025\n",
      "Epoch [13/100], Loss: 0.103234\n",
      "Epoch [14/100], Loss: 0.100522\n",
      "Epoch [15/100], Loss: 0.102046\n",
      "Epoch [16/100], Loss: 0.100106\n",
      "Epoch [17/100], Loss: 0.099715\n",
      "Epoch [18/100], Loss: 0.099806\n",
      "Epoch [19/100], Loss: 0.099060\n",
      "Epoch [20/100], Loss: 0.097470\n",
      "Epoch [21/100], Loss: 0.097673\n",
      "Epoch [22/100], Loss: 0.096505\n",
      "Epoch [23/100], Loss: 0.097280\n",
      "Epoch [24/100], Loss: 0.096701\n",
      "Epoch [25/100], Loss: 0.095620\n",
      "Epoch [26/100], Loss: 0.096284\n",
      "Epoch [27/100], Loss: 0.094842\n",
      "Epoch [28/100], Loss: 0.096739\n",
      "Epoch [29/100], Loss: 0.094498\n",
      "Epoch [30/100], Loss: 0.094793\n",
      "Epoch [31/100], Loss: 0.094767\n",
      "Epoch [32/100], Loss: 0.094031\n",
      "Epoch [33/100], Loss: 0.094144\n",
      "Epoch [34/100], Loss: 0.094099\n",
      "Epoch [35/100], Loss: 0.093417\n",
      "Epoch [36/100], Loss: 0.092421\n",
      "Epoch [37/100], Loss: 0.092161\n",
      "Epoch [38/100], Loss: 0.092203\n",
      "Epoch [39/100], Loss: 0.091983\n",
      "Epoch [40/100], Loss: 0.091758\n",
      "Epoch [41/100], Loss: 0.091825\n",
      "Epoch [42/100], Loss: 0.091278\n",
      "Epoch [43/100], Loss: 0.091616\n",
      "Epoch [44/100], Loss: 0.090613\n",
      "Epoch [45/100], Loss: 0.090818\n",
      "Epoch [46/100], Loss: 0.091312\n",
      "Epoch [47/100], Loss: 0.090568\n",
      "Epoch [48/100], Loss: 0.090308\n",
      "Epoch [49/100], Loss: 0.091820\n",
      "Epoch [50/100], Loss: 0.090329\n",
      "Epoch [51/100], Loss: 0.090070\n",
      "Epoch [52/100], Loss: 0.089917\n",
      "Epoch [53/100], Loss: 0.090589\n",
      "Epoch [54/100], Loss: 0.089334\n",
      "Epoch [55/100], Loss: 0.090415\n",
      "Epoch [56/100], Loss: 0.089559\n",
      "Epoch [57/100], Loss: 0.090181\n",
      "Epoch [58/100], Loss: 0.090165\n",
      "Epoch [59/100], Loss: 0.088897\n",
      "Epoch [60/100], Loss: 0.088844\n",
      "Epoch [61/100], Loss: 0.089329\n",
      "Epoch [62/100], Loss: 0.089008\n",
      "Epoch [63/100], Loss: 0.089971\n",
      "Epoch [64/100], Loss: 0.089347\n",
      "Epoch [65/100], Loss: 0.088639\n",
      "Epoch [66/100], Loss: 0.089409\n",
      "Epoch [67/100], Loss: 0.089603\n",
      "Epoch [68/100], Loss: 0.089632\n",
      "Epoch [69/100], Loss: 0.088440\n",
      "Epoch [70/100], Loss: 0.089418\n",
      "Epoch [71/100], Loss: 0.089373\n",
      "Epoch [72/100], Loss: 0.089516\n",
      "Epoch [73/100], Loss: 0.088975\n",
      "Epoch [74/100], Loss: 0.089719\n",
      "Early stopping triggered after 74 epochs.\n",
      "Transfer learning complete.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "patience = 5  \n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        preds = model(inputs)  # Forward pass\n",
    "        loss = criterion(preds, targets)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update last layer weights\n",
    "\n",
    "        total_loss += loss.item() * targets.size(0)  \n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples  \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        epochs_no_improve = 0  # Reset counter if loss improves\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break  # Stop training if no improvement for `patience` epochs\n",
    "\n",
    "print(\"Transfer learning complete.\")\n",
    "# torch.save(model.state_dict(), \"models/Regression_based/DNN_model_[256, 512, 512, 128]_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 0.084146\n",
      "Test Displacement Loss: 0.376728\n"
     ]
    }
   ],
   "source": [
    "avg_loss, displacement_loss = evaluate_model(model, val_loader)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE Loss: {avg_loss:.6f}\")\n",
    "print(f\"Test Displacement Loss: {displacement_loss:.6f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
