{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. loading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive - Nanyang Technological University\\Documents\\GitHub\\FYP\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cpu\n",
      "CUDA available: False\n",
      "No CUDA devices found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current CUDA device index (if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current CUDA device index:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"No CUDA devices found.\")\n",
    "\n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './Data/12_Sep_Readings/combined_data.csv'  # Update with the correct path\n",
    "cleaned_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import preprocess_dataset\n",
    "\n",
    "\n",
    "# X = cleaned_df.drop('XY', axis=1).values this should be the rest of values\n",
    "# y = cleaned_df['XY'].values this should be x and y axis values\n",
    "\n",
    "df_train, y_train, df_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled, X_test_scaled = preprocess_dataset(df_train, df_test)\n",
    "\n",
    "# X_val = X_val.astype(np.float)\n",
    "# X_val = torch.FloatTensor(X_val)\n",
    "# y_val = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to determine the optimal hyperparameters\n",
    "1. Loss function\n",
    "2. model depth and size, restricted to layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBuilder(nn.Module):\n",
    "\n",
    "    def __init__(self, no_features, layers, no_labels = 64):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        \n",
    "        # Input layer\n",
    "        layer_list.append(nn.Linear(no_features, layers[0]))\n",
    "        layer_list.append(nn.ReLU())\n",
    "        layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(layers) - 1):\n",
    "            layer_list.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            layer_list.append(nn.ReLU())\n",
    "            layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Output layer, 2 outputs\n",
    "        layer_list.append(nn.Linear(layers[-1], 2))\n",
    "        layer_list.append(nn.Sigmoid())  \n",
    "        # Define the MLP stack as a sequential model\n",
    "        self.mlp_stack = nn.Sequential(*layer_list)\n",
    "    def forward(self, x):\n",
    "        logits = self.mlp_stack(x)\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
