{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. loading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training has to be done with dropout as data is not always present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cpu\n",
      "CUDA available: False\n",
      "No CUDA devices found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import nn \n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current CUDA device index (if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current CUDA device index:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"No CUDA devices found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with the correct path\n",
    "# file_path = './Data/12_Sep_Readings/combined_data.csv'  \n",
    "# file_path = './Data/15_Nov_Readings/augmented_rssi_dataset.csv'\n",
    "file_path = './Data/15_Nov_Readings/combined_data.csv'\n",
    "cleaned_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tx_0 RSSI</th>\n",
       "      <th>Tx_0 Batt</th>\n",
       "      <th>Tx_0 Time</th>\n",
       "      <th>Tx_1 RSSI</th>\n",
       "      <th>Tx_1 Batt</th>\n",
       "      <th>Tx_1 Time</th>\n",
       "      <th>Tx_2 RSSI</th>\n",
       "      <th>Tx_2 Batt</th>\n",
       "      <th>Tx_2 Time</th>\n",
       "      <th>Tx_3 RSSI</th>\n",
       "      <th>...</th>\n",
       "      <th>Tx_5 Batt</th>\n",
       "      <th>Tx_5 Time</th>\n",
       "      <th>Tx_6 RSSI</th>\n",
       "      <th>Tx_6 Batt</th>\n",
       "      <th>Tx_6 Time</th>\n",
       "      <th>Tx_7 RSSI</th>\n",
       "      <th>Tx_7 Batt</th>\n",
       "      <th>Tx_7 Time</th>\n",
       "      <th>X_Coord</th>\n",
       "      <th>Y_Coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-58.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-65</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-59.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>4.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.07</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>4.12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-59.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>4.14</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.08</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-60.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-68</td>\n",
       "      <td>4.13</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.12</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.07</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-60.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-68</td>\n",
       "      <td>4.13</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>-66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>357.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>357.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>352.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>347.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>373.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>4.10</td>\n",
       "      <td>368.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>368.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>376.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>373.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>367.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>398.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.01</td>\n",
       "      <td>402.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>397.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>392.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>419.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>4.11</td>\n",
       "      <td>415.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>415.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.01</td>\n",
       "      <td>419.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>415.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>409.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>436.0</td>\n",
       "      <td>-66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>434.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.01</td>\n",
       "      <td>436.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>431.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tx_0 RSSI  Tx_0 Batt  Tx_0 Time  Tx_1 RSSI  Tx_1 Batt  Tx_1 Time  \\\n",
       "0         -58.0       4.16        0.0        -65       4.13        0.0   \n",
       "1         -59.0       4.11       21.0        -67       4.15       21.0   \n",
       "2         -59.0       4.14       38.0        -67       4.14       38.0   \n",
       "3         -60.0       4.16       57.0        -68       4.13       57.0   \n",
       "4         -60.0       4.16       74.0        -68       4.13       74.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1254      -74.0        NaN      357.0        -66        NaN      358.0   \n",
       "1255      -73.0       4.11      373.0        -67       4.10      368.0   \n",
       "1256      -73.0       4.11      394.0        -67        NaN      394.0   \n",
       "1257      -73.0       4.02      419.0        -67       4.11      415.0   \n",
       "1258      -73.0       4.10      436.0        -66        NaN      435.0   \n",
       "\n",
       "      Tx_2 RSSI  Tx_2 Batt  Tx_2 Time  Tx_3 RSSI  ...  Tx_5 Batt  Tx_5 Time  \\\n",
       "0         -72.0       4.13        0.0        NaN  ...       4.09        0.0   \n",
       "1         -72.0       4.11       20.0      -77.0  ...       4.07       17.0   \n",
       "2         -73.0        NaN       40.0      -77.0  ...       4.08       40.0   \n",
       "3         -73.0       4.12       56.0      -70.0  ...       4.07       54.0   \n",
       "4         -73.0       4.11       72.0      -70.0  ...        NaN       79.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1254      -67.0       4.07      357.0      -54.0  ...       4.00      357.0   \n",
       "1255      -67.0       4.08      368.0      -54.0  ...       4.00      376.0   \n",
       "1256      -68.0        NaN      398.0      -54.0  ...       4.01      402.0   \n",
       "1257      -68.0       4.08      415.0      -53.0  ...       4.01      419.0   \n",
       "1258      -68.0       4.07      434.0      -53.0  ...       4.01      436.0   \n",
       "\n",
       "      Tx_6 RSSI  Tx_6 Batt  Tx_6 Time  Tx_7 RSSI  Tx_7 Batt  Tx_7 Time  \\\n",
       "0         -81.0       4.12        0.0      -73.0       4.10        0.0   \n",
       "1         -80.0       4.12       15.0      -75.0        NaN       17.0   \n",
       "2         -79.0       4.13       38.0      -76.0       4.11       35.0   \n",
       "3         -83.0       4.13       50.0      -76.0        NaN       51.0   \n",
       "4         -81.0       4.14       78.0      -76.0        NaN       79.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1254      -76.0       4.11      352.0      -77.0       4.06      347.0   \n",
       "1255      -75.0       4.10      373.0      -77.0       4.07      367.0   \n",
       "1256      -75.0       4.11      397.0      -78.0       4.06      392.0   \n",
       "1257      -74.0       4.11      415.0      -78.0       4.06      409.0   \n",
       "1258      -75.0        NaN      437.0      -79.0       4.02      431.0   \n",
       "\n",
       "      X_Coord  Y_Coord  \n",
       "0           0        0  \n",
       "1           0        0  \n",
       "2           0        0  \n",
       "3           0        0  \n",
       "4           0        0  \n",
       "...       ...      ...  \n",
       "1254        5        6  \n",
       "1255        5        6  \n",
       "1256        5        6  \n",
       "1257        5        6  \n",
       "1258        5        6  \n",
       "\n",
       "[1259 rows x 26 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 10)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batt_columns = [col for col in cleaned_df.columns if 'Batt' in col]\n",
    "time_columns = [col for col in cleaned_df.columns if 'Time' in col]\n",
    "columns_to_drop = batt_columns+time_columns\n",
    "RSSI_columns = cleaned_df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "#Train the model without NAN values\n",
    "# cleaned_df = RSSI_columns.dropna()\n",
    "\n",
    "#Convert NaN values to -100\n",
    "cleaned_df = RSSI_columns.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tx_0 RSSI</th>\n",
       "      <th>Tx_1 RSSI</th>\n",
       "      <th>Tx_2 RSSI</th>\n",
       "      <th>Tx_3 RSSI</th>\n",
       "      <th>Tx_4 RSSI</th>\n",
       "      <th>Tx_5 RSSI</th>\n",
       "      <th>Tx_6 RSSI</th>\n",
       "      <th>Tx_7 RSSI</th>\n",
       "      <th>X_Coord</th>\n",
       "      <th>Y_Coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-58.0</td>\n",
       "      <td>-65</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-59.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-59.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-60.0</td>\n",
       "      <td>-68</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-60.0</td>\n",
       "      <td>-68</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>-74.0</td>\n",
       "      <td>-66</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-73.0</td>\n",
       "      <td>-66</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tx_0 RSSI  Tx_1 RSSI  Tx_2 RSSI  Tx_3 RSSI  Tx_4 RSSI  Tx_5 RSSI  \\\n",
       "0         -58.0        -65      -72.0        0.0      -74.0      -75.0   \n",
       "1         -59.0        -67      -72.0      -77.0      -72.0      -76.0   \n",
       "2         -59.0        -67      -73.0      -77.0      -70.0      -81.0   \n",
       "3         -60.0        -68      -73.0      -70.0      -72.0      -81.0   \n",
       "4         -60.0        -68      -73.0      -70.0      -71.0      -82.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1254      -74.0        -66      -67.0      -54.0      -69.0      -66.0   \n",
       "1255      -73.0        -67      -67.0      -54.0      -69.0      -66.0   \n",
       "1256      -73.0        -67      -68.0      -54.0      -70.0      -65.0   \n",
       "1257      -73.0        -67      -68.0      -53.0      -70.0      -66.0   \n",
       "1258      -73.0        -66      -68.0      -53.0      -70.0      -65.0   \n",
       "\n",
       "      Tx_6 RSSI  Tx_7 RSSI  X_Coord  Y_Coord  \n",
       "0         -81.0      -73.0        0        0  \n",
       "1         -80.0      -75.0        0        0  \n",
       "2         -79.0      -76.0        0        0  \n",
       "3         -83.0      -76.0        0        0  \n",
       "4         -81.0      -76.0        0        0  \n",
       "...         ...        ...      ...      ...  \n",
       "1254      -76.0      -77.0        5        6  \n",
       "1255      -75.0      -77.0        5        6  \n",
       "1256      -75.0      -78.0        5        6  \n",
       "1257      -74.0      -78.0        5        6  \n",
       "1258      -75.0      -79.0        5        6  \n",
       "\n",
       "[1259 rows x 10 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "       Tx_0 RSSI  Tx_1 RSSI  Tx_2 RSSI  Tx_3 RSSI  Tx_4 RSSI  Tx_5 RSSI  \\\n",
      "243       -65.0        -56      -69.0      -61.0      -68.0      -72.0   \n",
      "514       -75.0        -68      -75.0      -68.0      -65.0      -58.0   \n",
      "966       -84.0        -64      -70.0      -73.0      -69.0      -66.0   \n",
      "199       -71.0        -80      -76.0      -78.0      -70.0      -79.0   \n",
      "270       -68.0        -62      -60.0      -64.0        0.0      -70.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1044      -72.0        -72      -78.0      -64.0      -72.0      -71.0   \n",
      "1095      -73.0        -67      -70.0      -64.0      -64.0      -63.0   \n",
      "1130      -75.0        -66      -77.0        0.0      -67.0      -62.0   \n",
      "860       -70.0        -68      -68.0      -72.0      -75.0      -80.0   \n",
      "1126      -74.0        -66      -77.0      -85.0      -68.0      -62.0   \n",
      "\n",
      "      Tx_6 RSSI  Tx_7 RSSI  \n",
      "243       -78.0      -76.0  \n",
      "514       -64.0      -68.0  \n",
      "966       -79.0      -71.0  \n",
      "199         0.0      -75.0  \n",
      "270       -76.0      -72.0  \n",
      "...         ...        ...  \n",
      "1044      -62.0      -68.0  \n",
      "1095      -67.0      -71.0  \n",
      "1130      -73.0      -69.0  \n",
      "860       -69.0      -71.0  \n",
      "1126      -73.0      -69.0  \n",
      "\n",
      "[1007 rows x 8 columns]\n",
      "X_test:\n",
      "       Tx_0 RSSI  Tx_1 RSSI  Tx_2 RSSI  Tx_3 RSSI  Tx_4 RSSI  Tx_5 RSSI  \\\n",
      "76        -70.0        -56      -62.0      -64.0      -80.0      -83.0   \n",
      "1026      -71.0        -60      -67.0      -66.0      -79.0      -71.0   \n",
      "43        -64.0        -60      -74.0      -70.0        0.0      -70.0   \n",
      "666       -79.0        -80      -78.0      -67.0      -63.0      -69.0   \n",
      "529       -84.0        -72      -79.0      -75.0      -67.0      -61.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "430       -71.0        -81      -69.0      -60.0      -72.0      -65.0   \n",
      "32        -62.0        -64      -82.0      -73.0      -82.0      -76.0   \n",
      "156       -68.0        -69      -71.0      -68.0      -71.0        0.0   \n",
      "376       -57.0        -61      -67.0      -72.0      -73.0      -70.0   \n",
      "620       -79.0        -82      -74.0      -70.0      -65.0      -75.0   \n",
      "\n",
      "      Tx_6 RSSI  Tx_7 RSSI  \n",
      "76          0.0      -83.0  \n",
      "1026      -76.0      -70.0  \n",
      "43        -78.0      -74.0  \n",
      "666       -61.0      -71.0  \n",
      "529       -59.0      -73.0  \n",
      "...         ...        ...  \n",
      "430       -78.0      -71.0  \n",
      "32        -77.0      -76.0  \n",
      "156       -80.0      -68.0  \n",
      "376       -81.0        0.0  \n",
      "620       -75.0      -82.0  \n",
      "\n",
      "[252 rows x 8 columns]\n",
      "Y_train:\n",
      "       X_Coord  Y_Coord\n",
      "243         0        3\n",
      "514         7        3\n",
      "966         3        0\n",
      "199         2        2\n",
      "270         0        5\n",
      "...       ...      ...\n",
      "1044        3        6\n",
      "1095        5        5\n",
      "1130        5        1\n",
      "860         3        7\n",
      "1126        5        1\n",
      "\n",
      "[1007 rows x 2 columns]\n",
      "Y_test:\n",
      "       X_Coord  Y_Coord\n",
      "76          0        6\n",
      "1026        3        4\n",
      "43          0        4\n",
      "666         7        2\n",
      "529         7        1\n",
      "...       ...      ...\n",
      "430         2        5\n",
      "32          0        2\n",
      "156         1        0\n",
      "376         1        1\n",
      "620         7        6\n",
      "\n",
      "[252 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from common_utils import preprocess_dataset\n",
    "\n",
    "X = cleaned_df[['Tx_0 RSSI', 'Tx_1 RSSI', 'Tx_2 RSSI', 'Tx_3 RSSI', 'Tx_4 RSSI', 'Tx_5 RSSI', 'Tx_6 RSSI', 'Tx_7 RSSI']]\n",
    "# X = cleaned_df[['Tx_0 RSSI_Avg', 'Tx_1 RSSI_Avg', 'Tx_2 RSSI_Avg', 'Tx_3 RSSI_Avg', 'Tx_4 RSSI_Avg', 'Tx_5 RSSI_Avg', 'Tx_6 RSSI_Avg', 'Tx_7 RSSI_Avg']]\n",
    "\n",
    "\n",
    "\n",
    "Y = cleaned_df[['X_Coord', 'Y_Coord']]\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the results\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"Y_train:\\n\", Y_train)\n",
    "print(\"Y_test:\\n\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to determine the optimal hyperparameters\n",
    "1. Loss function\n",
    "2. model depth and size, restricted to 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBuilder(nn.Module):\n",
    "\n",
    "    def __init__(self, no_features, layers, no_labels = 64):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        \n",
    "        # Input layer\n",
    "        layer_list.append(nn.Linear(no_features, layers[0]))\n",
    "        layer_list.append(nn.ReLU())\n",
    "        layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(layers) - 1):\n",
    "            layer_list.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            layer_list.append(nn.ReLU())\n",
    "            layer_list.append(nn.Dropout(p=0.2))\n",
    "\n",
    "        # Output layer, 2 outputs\n",
    "        layer_list.append(nn.Linear(layers[-1], 2))\n",
    " \n",
    "        # Define the MLP stack as a sequential model\n",
    "        self.mlp_stack = nn.Sequential(*layer_list)\n",
    "\n",
    "        self._initialize_weights() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.mlp_stack(x)\n",
    "        return logits\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.mlp_stack:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                # Use Kaiming initialization for ReLU activations\n",
    "                nn.init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "\n",
    "# Normalize the input data (RSSI values) for both training and testing sets\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Initialize the scaler for the target coordinates (X_Coord, Y_Coord)\n",
    "scaler_Y = MinMaxScaler()\n",
    "\n",
    "# Normalize the target coordinates (X_Coord, Y_Coord) for both training and testing sets\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "# Convert the normalized data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for the training set\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Shuffle is typically False for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# joblib.dump(scaler_X, './models/scales/scaler_X.pkl')\n",
    "# joblib.dump(scaler_Y, './models/scales/scaler_Y.pkl')\n",
    "\n",
    "scaler_X = joblib.load('./models/scales/scaler_X.pkl')\n",
    "scaler_Y = joblib.load('./models/scales/scaler_Y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = loss_fn(outputs, targets)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)  # Average loss for the epoch\n",
    "    return avg_loss\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # No gradients needed during testing\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = loss_fn(outputs, targets)  # Compute the loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)  # Average loss for the epoch\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        \"\"\"\n",
    "        patience: number of epochs to wait for improvement in validation loss before stopping\n",
    "        delta: minimum change to consider as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')  # Initialize the best loss as infinity\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0  # Reset the counter if there's an improvement\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32], [64], [128], [256], [32, 32], [32, 64], [32, 128], [32, 256], [64, 32], [64, 64], [64, 128], [64, 256], [128, 32], [128, 64], [128, 128], [128, 256], [256, 32], [256, 64], [256, 128], [256, 256], [32, 32, 32], [32, 32, 64], [32, 32, 128], [32, 32, 256], [32, 64, 32], [32, 64, 64], [32, 64, 128], [32, 64, 256], [32, 128, 32], [32, 128, 64], [32, 128, 128], [32, 128, 256], [32, 256, 32], [32, 256, 64], [32, 256, 128], [32, 256, 256], [64, 32, 32], [64, 32, 64], [64, 32, 128], [64, 32, 256], [64, 64, 32], [64, 64, 64], [64, 64, 128], [64, 64, 256], [64, 128, 32], [64, 128, 64], [64, 128, 128], [64, 128, 256], [64, 256, 32], [64, 256, 64], [64, 256, 128], [64, 256, 256], [128, 32, 32], [128, 32, 64], [128, 32, 128], [128, 32, 256], [128, 64, 32], [128, 64, 64], [128, 64, 128], [128, 64, 256], [128, 128, 32], [128, 128, 64], [128, 128, 128], [128, 128, 256], [128, 256, 32], [128, 256, 64], [128, 256, 128], [128, 256, 256], [256, 32, 32], [256, 32, 64], [256, 32, 128], [256, 32, 256], [256, 64, 32], [256, 64, 64], [256, 64, 128], [256, 64, 256], [256, 128, 32], [256, 128, 64], [256, 128, 128], [256, 128, 256], [256, 256, 32], [256, 256, 64], [256, 256, 128], [256, 256, 256]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "x = [32, 64, 128, 256]\n",
    "\n",
    "# Generate all combinations for each possible length (1 to 4 elements)\n",
    "combinations = []\n",
    "for r in range(1, 4):  # r goes from 1 to 3\n",
    "    combinations.extend(itertools.product(x, repeat=r))\n",
    "\n",
    "# Convert to list format and print\n",
    "combinations = [list(comb) for comb in combinations]\n",
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def determine_depth_and_width(layer_combinations, epochs):\n",
    "    results = []  # Store results for all layer configurations\n",
    "    training_times = []  # List to store training times\n",
    "\n",
    "    for layers in layer_combinations:\n",
    "        model = MLPBuilder(no_features=X_train.shape[1], layers=layers)\n",
    "        criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "        l2_weight_decay = 1e-4\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=l2_weight_decay)\n",
    "\n",
    "        # Training loop\n",
    "        print(f\"{'=' * 50}\\n\"\n",
    "              f\"Layers: {layers}\"\n",
    "              )\n",
    "\n",
    "        start_time = time.time()  # Start timing the training process\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Train the model\n",
    "            train_loss = train_loop(train_loader, model, criterion, optimizer)\n",
    "            \n",
    "            # Test the model\n",
    "            test_loss = test_loop(test_loader, model, criterion)\n",
    "\n",
    "            # Print average loss for the epoch\n",
    "            print(f\"Epoch: [{epoch + 1:>3}/{epochs:<3}]\"\n",
    "                  f\"Train Loss: {train_loss:.6f}  |  \"\n",
    "                  f\"Test Loss: {test_loss:.6f}\\n\")\n",
    "\n",
    "            # Save results only for the last epoch\n",
    "            if epoch == epochs - 1:\n",
    "                results.append({\n",
    "                    'layers': layers,\n",
    "                    'train_loss': train_loss,\n",
    "                    'test_loss': test_loss,\n",
    "                })\n",
    "\n",
    "        print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "        end_time = time.time()  # End timing the training process\n",
    "        training_time = end_time - start_time  # Calculate total training time\n",
    "        training_times.append(training_time)  # Append the training time for this configuration\n",
    "\n",
    "    return results, training_times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the best layout configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 10\n",
    "# results, training_times = determine_depth_and_width(combinations, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_accuracies = [result['test_correct'] * 100 for result in results]  # List of test accuracies (in percentage)\n",
    "# layer_configs = [str(result['layers']) for result in results]  # Layer configurations as strings\n",
    "\n",
    "# # Create a scatter plot for Test Accuracy vs. Training Time\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for i, layer_size in enumerate(layer_configs):\n",
    "#     plt.scatter(training_times[i], test_accuracies[i], color='b')  # Plot point\n",
    "#     plt.text(training_times[i], test_accuracies[i], layer_size, fontsize=9, ha='right')  # Add text label for each point\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('Training Time (seconds)')\n",
    "# plt.ylabel('Test Accuracy (%)')\n",
    "# plt.title('Test Accuracy vs Training Time for Different Layer Configurations')\n",
    "\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Best Model is seen to be [256,128,32] with the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [  1/200]Train Loss: 0.261277  |  Test Loss: 0.117032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [  2/200]Train Loss: 0.141127  |  Test Loss: 0.089083\n",
      "\n",
      "Epoch: [  3/200]Train Loss: 0.109259  |  Test Loss: 0.072061\n",
      "\n",
      "Epoch: [  4/200]Train Loss: 0.095798  |  Test Loss: 0.075176\n",
      "\n",
      "Epoch: [  5/200]Train Loss: 0.091063  |  Test Loss: 0.066209\n",
      "\n",
      "Epoch: [  6/200]Train Loss: 0.083346  |  Test Loss: 0.058758\n",
      "\n",
      "Epoch: [  7/200]Train Loss: 0.077633  |  Test Loss: 0.053980\n",
      "\n",
      "Epoch: [  8/200]Train Loss: 0.079488  |  Test Loss: 0.050821\n",
      "\n",
      "Epoch: [  9/200]Train Loss: 0.075219  |  Test Loss: 0.050963\n",
      "\n",
      "Epoch: [ 10/200]Train Loss: 0.069407  |  Test Loss: 0.047863\n",
      "\n",
      "Epoch: [ 11/200]Train Loss: 0.071835  |  Test Loss: 0.045527\n",
      "\n",
      "Epoch: [ 12/200]Train Loss: 0.068840  |  Test Loss: 0.048412\n",
      "\n",
      "Epoch: [ 13/200]Train Loss: 0.064546  |  Test Loss: 0.044829\n",
      "\n",
      "Epoch: [ 14/200]Train Loss: 0.063578  |  Test Loss: 0.042471\n",
      "\n",
      "Epoch: [ 15/200]Train Loss: 0.058694  |  Test Loss: 0.038774\n",
      "\n",
      "Epoch: [ 16/200]Train Loss: 0.059770  |  Test Loss: 0.041216\n",
      "\n",
      "Epoch: [ 17/200]Train Loss: 0.061237  |  Test Loss: 0.041084\n",
      "\n",
      "Epoch: [ 18/200]Train Loss: 0.057647  |  Test Loss: 0.038494\n",
      "\n",
      "Epoch: [ 19/200]Train Loss: 0.056823  |  Test Loss: 0.038982\n",
      "\n",
      "Epoch: [ 20/200]Train Loss: 0.055066  |  Test Loss: 0.035539\n",
      "\n",
      "Epoch: [ 21/200]Train Loss: 0.052216  |  Test Loss: 0.037455\n",
      "\n",
      "Epoch: [ 22/200]Train Loss: 0.051706  |  Test Loss: 0.033646\n",
      "\n",
      "Epoch: [ 23/200]Train Loss: 0.051832  |  Test Loss: 0.031911\n",
      "\n",
      "Epoch: [ 24/200]Train Loss: 0.048579  |  Test Loss: 0.033139\n",
      "\n",
      "Epoch: [ 25/200]Train Loss: 0.049634  |  Test Loss: 0.031476\n",
      "\n",
      "Epoch: [ 26/200]Train Loss: 0.049098  |  Test Loss: 0.032994\n",
      "\n",
      "Epoch: [ 27/200]Train Loss: 0.045916  |  Test Loss: 0.029161\n",
      "\n",
      "Epoch: [ 28/200]Train Loss: 0.045778  |  Test Loss: 0.033693\n",
      "\n",
      "Epoch: [ 29/200]Train Loss: 0.044909  |  Test Loss: 0.026539\n",
      "\n",
      "Epoch: [ 30/200]Train Loss: 0.042195  |  Test Loss: 0.030684\n",
      "\n",
      "Epoch: [ 31/200]Train Loss: 0.043749  |  Test Loss: 0.027460\n",
      "\n",
      "Epoch: [ 32/200]Train Loss: 0.041187  |  Test Loss: 0.027429\n",
      "\n",
      "Epoch: [ 33/200]Train Loss: 0.043014  |  Test Loss: 0.028697\n",
      "\n",
      "Epoch: [ 34/200]Train Loss: 0.040045  |  Test Loss: 0.025602\n",
      "\n",
      "Epoch: [ 35/200]Train Loss: 0.040092  |  Test Loss: 0.026495\n",
      "\n",
      "Epoch: [ 36/200]Train Loss: 0.038243  |  Test Loss: 0.025683\n",
      "\n",
      "Epoch: [ 37/200]Train Loss: 0.039676  |  Test Loss: 0.025089\n",
      "\n",
      "Epoch: [ 38/200]Train Loss: 0.039573  |  Test Loss: 0.026306\n",
      "\n",
      "Epoch: [ 39/200]Train Loss: 0.038646  |  Test Loss: 0.024803\n",
      "\n",
      "Epoch: [ 40/200]Train Loss: 0.037674  |  Test Loss: 0.023748\n",
      "\n",
      "Epoch: [ 41/200]Train Loss: 0.035860  |  Test Loss: 0.022504\n",
      "\n",
      "Epoch: [ 42/200]Train Loss: 0.035604  |  Test Loss: 0.022240\n",
      "\n",
      "Epoch: [ 43/200]Train Loss: 0.035939  |  Test Loss: 0.022752\n",
      "\n",
      "Epoch: [ 44/200]Train Loss: 0.034839  |  Test Loss: 0.021036\n",
      "\n",
      "Epoch: [ 45/200]Train Loss: 0.035795  |  Test Loss: 0.021705\n",
      "\n",
      "Epoch: [ 46/200]Train Loss: 0.032569  |  Test Loss: 0.020203\n",
      "\n",
      "Epoch: [ 47/200]Train Loss: 0.033188  |  Test Loss: 0.020181\n",
      "\n",
      "Epoch: [ 48/200]Train Loss: 0.032694  |  Test Loss: 0.021563\n",
      "\n",
      "Epoch: [ 49/200]Train Loss: 0.034105  |  Test Loss: 0.020771\n",
      "\n",
      "Epoch: [ 50/200]Train Loss: 0.033479  |  Test Loss: 0.020271\n",
      "\n",
      "Epoch: [ 51/200]Train Loss: 0.031580  |  Test Loss: 0.018750\n",
      "\n",
      "Epoch: [ 52/200]Train Loss: 0.031887  |  Test Loss: 0.019005\n",
      "\n",
      "Epoch: [ 53/200]Train Loss: 0.031360  |  Test Loss: 0.020137\n",
      "\n",
      "Epoch: [ 54/200]Train Loss: 0.030907  |  Test Loss: 0.018509\n",
      "\n",
      "Epoch: [ 55/200]Train Loss: 0.028789  |  Test Loss: 0.017329\n",
      "\n",
      "Epoch: [ 56/200]Train Loss: 0.029606  |  Test Loss: 0.018270\n",
      "\n",
      "Epoch: [ 57/200]Train Loss: 0.028864  |  Test Loss: 0.017791\n",
      "\n",
      "Epoch: [ 58/200]Train Loss: 0.028580  |  Test Loss: 0.017038\n",
      "\n",
      "Epoch: [ 59/200]Train Loss: 0.029052  |  Test Loss: 0.017180\n",
      "\n",
      "Epoch: [ 60/200]Train Loss: 0.027292  |  Test Loss: 0.015618\n",
      "\n",
      "Epoch: [ 61/200]Train Loss: 0.029539  |  Test Loss: 0.016499\n",
      "\n",
      "Epoch: [ 62/200]Train Loss: 0.026593  |  Test Loss: 0.016266\n",
      "\n",
      "Epoch: [ 63/200]Train Loss: 0.026960  |  Test Loss: 0.015110\n",
      "\n",
      "Epoch: [ 64/200]Train Loss: 0.026348  |  Test Loss: 0.017278\n",
      "\n",
      "Epoch: [ 65/200]Train Loss: 0.027626  |  Test Loss: 0.016885\n",
      "\n",
      "Epoch: [ 66/200]Train Loss: 0.026140  |  Test Loss: 0.015763\n",
      "\n",
      "Epoch: [ 67/200]Train Loss: 0.026027  |  Test Loss: 0.015729\n",
      "\n",
      "Epoch: [ 68/200]Train Loss: 0.026930  |  Test Loss: 0.017549\n",
      "\n",
      "Epoch: [ 69/200]Train Loss: 0.026403  |  Test Loss: 0.013882\n",
      "\n",
      "Epoch: [ 70/200]Train Loss: 0.023491  |  Test Loss: 0.014958\n",
      "\n",
      "Epoch: [ 71/200]Train Loss: 0.023987  |  Test Loss: 0.014362\n",
      "\n",
      "Epoch: [ 72/200]Train Loss: 0.024793  |  Test Loss: 0.014575\n",
      "\n",
      "Epoch: [ 73/200]Train Loss: 0.024414  |  Test Loss: 0.014327\n",
      "\n",
      "Epoch: [ 74/200]Train Loss: 0.024402  |  Test Loss: 0.014840\n",
      "\n",
      "Epoch: [ 75/200]Train Loss: 0.023934  |  Test Loss: 0.013900\n",
      "\n",
      "Epoch: [ 76/200]Train Loss: 0.022160  |  Test Loss: 0.014474\n",
      "\n",
      "Epoch: [ 77/200]Train Loss: 0.022418  |  Test Loss: 0.013559\n",
      "\n",
      "Epoch: [ 78/200]Train Loss: 0.022659  |  Test Loss: 0.013776\n",
      "\n",
      "Epoch: [ 79/200]Train Loss: 0.023224  |  Test Loss: 0.014157\n",
      "\n",
      "Epoch: [ 80/200]Train Loss: 0.021099  |  Test Loss: 0.014077\n",
      "\n",
      "Epoch: [ 81/200]Train Loss: 0.022191  |  Test Loss: 0.013230\n",
      "\n",
      "Epoch: [ 82/200]Train Loss: 0.021086  |  Test Loss: 0.013809\n",
      "\n",
      "Epoch: [ 83/200]Train Loss: 0.021949  |  Test Loss: 0.014077\n",
      "\n",
      "Epoch: [ 84/200]Train Loss: 0.020310  |  Test Loss: 0.012297\n",
      "\n",
      "Epoch: [ 85/200]Train Loss: 0.021501  |  Test Loss: 0.012409\n",
      "\n",
      "Epoch: [ 86/200]Train Loss: 0.021854  |  Test Loss: 0.013230\n",
      "\n",
      "Epoch: [ 87/200]Train Loss: 0.021646  |  Test Loss: 0.014081\n",
      "\n",
      "Epoch: [ 88/200]Train Loss: 0.021066  |  Test Loss: 0.013092\n",
      "\n",
      "Epoch: [ 89/200]Train Loss: 0.019533  |  Test Loss: 0.013065\n",
      "\n",
      "Epoch: [ 90/200]Train Loss: 0.020368  |  Test Loss: 0.012327\n",
      "\n",
      "Epoch: [ 91/200]Train Loss: 0.019585  |  Test Loss: 0.011685\n",
      "\n",
      "Epoch: [ 92/200]Train Loss: 0.020021  |  Test Loss: 0.012198\n",
      "\n",
      "Epoch: [ 93/200]Train Loss: 0.019235  |  Test Loss: 0.011994\n",
      "\n",
      "Epoch: [ 94/200]Train Loss: 0.019763  |  Test Loss: 0.013035\n",
      "\n",
      "Epoch: [ 95/200]Train Loss: 0.018828  |  Test Loss: 0.012222\n",
      "\n",
      "Epoch: [ 96/200]Train Loss: 0.019808  |  Test Loss: 0.011612\n",
      "\n",
      "Epoch: [ 97/200]Train Loss: 0.018883  |  Test Loss: 0.011759\n",
      "\n",
      "Epoch: [ 98/200]Train Loss: 0.019017  |  Test Loss: 0.011881\n",
      "\n",
      "Epoch: [ 99/200]Train Loss: 0.019491  |  Test Loss: 0.010851\n",
      "\n",
      "Epoch: [100/200]Train Loss: 0.019133  |  Test Loss: 0.012262\n",
      "\n",
      "Epoch: [101/200]Train Loss: 0.018653  |  Test Loss: 0.010861\n",
      "\n",
      "Epoch: [102/200]Train Loss: 0.017180  |  Test Loss: 0.012069\n",
      "\n",
      "Epoch: [103/200]Train Loss: 0.017022  |  Test Loss: 0.011491\n",
      "\n",
      "Epoch: [104/200]Train Loss: 0.018310  |  Test Loss: 0.011346\n",
      "\n",
      "Epoch: [105/200]Train Loss: 0.018247  |  Test Loss: 0.013490\n",
      "\n",
      "Epoch: [106/200]Train Loss: 0.018615  |  Test Loss: 0.010207\n",
      "\n",
      "Epoch: [107/200]Train Loss: 0.017650  |  Test Loss: 0.010961\n",
      "\n",
      "Epoch: [108/200]Train Loss: 0.017610  |  Test Loss: 0.011737\n",
      "\n",
      "Epoch: [109/200]Train Loss: 0.017269  |  Test Loss: 0.011002\n",
      "\n",
      "Epoch: [110/200]Train Loss: 0.017423  |  Test Loss: 0.010271\n",
      "\n",
      "Epoch: [111/200]Train Loss: 0.016868  |  Test Loss: 0.011401\n",
      "\n",
      "Epoch: [112/200]Train Loss: 0.017166  |  Test Loss: 0.010475\n",
      "\n",
      "Epoch: [113/200]Train Loss: 0.016517  |  Test Loss: 0.011227\n",
      "\n",
      "Epoch: [114/200]Train Loss: 0.017514  |  Test Loss: 0.009778\n",
      "\n",
      "Epoch: [115/200]Train Loss: 0.016572  |  Test Loss: 0.011302\n",
      "\n",
      "Epoch: [116/200]Train Loss: 0.015821  |  Test Loss: 0.010159\n",
      "\n",
      "Epoch: [117/200]Train Loss: 0.016058  |  Test Loss: 0.010780\n",
      "\n",
      "Epoch: [118/200]Train Loss: 0.016486  |  Test Loss: 0.010138\n",
      "\n",
      "Epoch: [119/200]Train Loss: 0.014827  |  Test Loss: 0.010430\n",
      "\n",
      "Epoch: [120/200]Train Loss: 0.015420  |  Test Loss: 0.009996\n",
      "\n",
      "Epoch: [121/200]Train Loss: 0.014861  |  Test Loss: 0.010634\n",
      "\n",
      "Epoch: [122/200]Train Loss: 0.014409  |  Test Loss: 0.009712\n",
      "\n",
      "Epoch: [123/200]Train Loss: 0.015390  |  Test Loss: 0.010007\n",
      "\n",
      "Epoch: [124/200]Train Loss: 0.015088  |  Test Loss: 0.009865\n",
      "\n",
      "Epoch: [125/200]Train Loss: 0.014915  |  Test Loss: 0.010079\n",
      "\n",
      "Epoch: [126/200]Train Loss: 0.015752  |  Test Loss: 0.009711\n",
      "\n",
      "Epoch: [127/200]Train Loss: 0.015097  |  Test Loss: 0.009734\n",
      "\n",
      "Epoch: [128/200]Train Loss: 0.014319  |  Test Loss: 0.010518\n",
      "\n",
      "Epoch: [129/200]Train Loss: 0.014387  |  Test Loss: 0.009662\n",
      "\n",
      "Epoch: [130/200]Train Loss: 0.014047  |  Test Loss: 0.009534\n",
      "\n",
      "Epoch: [131/200]Train Loss: 0.014470  |  Test Loss: 0.009537\n",
      "\n",
      "Epoch: [132/200]Train Loss: 0.013473  |  Test Loss: 0.009147\n",
      "\n",
      "Epoch: [133/200]Train Loss: 0.013773  |  Test Loss: 0.009832\n",
      "\n",
      "Epoch: [134/200]Train Loss: 0.013596  |  Test Loss: 0.008914\n",
      "\n",
      "Epoch: [135/200]Train Loss: 0.014003  |  Test Loss: 0.009457\n",
      "\n",
      "Epoch: [136/200]Train Loss: 0.015779  |  Test Loss: 0.009097\n",
      "\n",
      "Epoch: [137/200]Train Loss: 0.013165  |  Test Loss: 0.009045\n",
      "\n",
      "Epoch: [138/200]Train Loss: 0.012963  |  Test Loss: 0.008871\n",
      "\n",
      "Epoch: [139/200]Train Loss: 0.014060  |  Test Loss: 0.008894\n",
      "\n",
      "Epoch: [140/200]Train Loss: 0.013228  |  Test Loss: 0.008491\n",
      "\n",
      "Epoch: [141/200]Train Loss: 0.012766  |  Test Loss: 0.008684\n",
      "\n",
      "Epoch: [142/200]Train Loss: 0.012845  |  Test Loss: 0.008081\n",
      "\n",
      "Epoch: [143/200]Train Loss: 0.012979  |  Test Loss: 0.008400\n",
      "\n",
      "Epoch: [144/200]Train Loss: 0.013306  |  Test Loss: 0.008732\n",
      "\n",
      "Epoch: [145/200]Train Loss: 0.012147  |  Test Loss: 0.008496\n",
      "\n",
      "Epoch: [146/200]Train Loss: 0.013411  |  Test Loss: 0.009001\n",
      "\n",
      "Epoch: [147/200]Train Loss: 0.013613  |  Test Loss: 0.008682\n",
      "\n",
      "Epoch: [148/200]Train Loss: 0.012578  |  Test Loss: 0.008794\n",
      "\n",
      "Epoch: [149/200]Train Loss: 0.012759  |  Test Loss: 0.008571\n",
      "\n",
      "Epoch: [150/200]Train Loss: 0.012451  |  Test Loss: 0.008164\n",
      "\n",
      "Epoch: [151/200]Train Loss: 0.012797  |  Test Loss: 0.008421\n",
      "\n",
      "Epoch: [152/200]Train Loss: 0.012950  |  Test Loss: 0.007834\n",
      "\n",
      "Epoch: [153/200]Train Loss: 0.012265  |  Test Loss: 0.007744\n",
      "\n",
      "Epoch: [154/200]Train Loss: 0.012846  |  Test Loss: 0.008799\n",
      "\n",
      "Epoch: [155/200]Train Loss: 0.012156  |  Test Loss: 0.007996\n",
      "\n",
      "Epoch: [156/200]Train Loss: 0.011486  |  Test Loss: 0.008194\n",
      "\n",
      "Epoch: [157/200]Train Loss: 0.012543  |  Test Loss: 0.007863\n",
      "\n",
      "Epoch: [158/200]Train Loss: 0.011285  |  Test Loss: 0.008370\n",
      "\n",
      "Epoch: [159/200]Train Loss: 0.011494  |  Test Loss: 0.008283\n",
      "\n",
      "Epoch: [160/200]Train Loss: 0.011156  |  Test Loss: 0.008734\n",
      "\n",
      "Epoch: [161/200]Train Loss: 0.011762  |  Test Loss: 0.007751\n",
      "\n",
      "Epoch: [162/200]Train Loss: 0.010895  |  Test Loss: 0.007912\n",
      "\n",
      "Epoch: [163/200]Train Loss: 0.011634  |  Test Loss: 0.007718\n",
      "\n",
      "Epoch: [164/200]Train Loss: 0.010465  |  Test Loss: 0.007793\n",
      "\n",
      "Epoch: [165/200]Train Loss: 0.011457  |  Test Loss: 0.008335\n",
      "\n",
      "Epoch: [166/200]Train Loss: 0.011774  |  Test Loss: 0.008095\n",
      "\n",
      "Epoch: [167/200]Train Loss: 0.011171  |  Test Loss: 0.008402\n",
      "\n",
      "Epoch: [168/200]Train Loss: 0.011540  |  Test Loss: 0.007944\n",
      "\n",
      "Epoch: [169/200]Train Loss: 0.010537  |  Test Loss: 0.007818\n",
      "\n",
      "Epoch: [170/200]Train Loss: 0.011814  |  Test Loss: 0.007290\n",
      "\n",
      "Epoch: [171/200]Train Loss: 0.010764  |  Test Loss: 0.008367\n",
      "\n",
      "Epoch: [172/200]Train Loss: 0.010996  |  Test Loss: 0.007155\n",
      "\n",
      "Epoch: [173/200]Train Loss: 0.010908  |  Test Loss: 0.008400\n",
      "\n",
      "Epoch: [174/200]Train Loss: 0.011328  |  Test Loss: 0.007650\n",
      "\n",
      "Epoch: [175/200]Train Loss: 0.009751  |  Test Loss: 0.006727\n",
      "\n",
      "Epoch: [176/200]Train Loss: 0.010812  |  Test Loss: 0.007011\n",
      "\n",
      "Epoch: [177/200]Train Loss: 0.011657  |  Test Loss: 0.007314\n",
      "\n",
      "Epoch: [178/200]Train Loss: 0.009971  |  Test Loss: 0.007430\n",
      "\n",
      "Epoch: [179/200]Train Loss: 0.011032  |  Test Loss: 0.007218\n",
      "\n",
      "Epoch: [180/200]Train Loss: 0.010175  |  Test Loss: 0.006781\n",
      "\n",
      "Epoch: [181/200]Train Loss: 0.010289  |  Test Loss: 0.007294\n",
      "\n",
      "Epoch: [182/200]Train Loss: 0.010679  |  Test Loss: 0.007431\n",
      "\n",
      "Epoch: [183/200]Train Loss: 0.011076  |  Test Loss: 0.007676\n",
      "\n",
      "Epoch: [184/200]Train Loss: 0.011101  |  Test Loss: 0.006767\n",
      "\n",
      "Epoch: [185/200]Train Loss: 0.010473  |  Test Loss: 0.007282\n",
      "\n",
      "Epoch: [186/200]Train Loss: 0.010422  |  Test Loss: 0.006782\n",
      "\n",
      "Epoch: [187/200]Train Loss: 0.009861  |  Test Loss: 0.006883\n",
      "\n",
      "Epoch: [188/200]Train Loss: 0.010226  |  Test Loss: 0.007089\n",
      "\n",
      "Epoch: [189/200]Train Loss: 0.010168  |  Test Loss: 0.006935\n",
      "\n",
      "Epoch: [190/200]Train Loss: 0.009792  |  Test Loss: 0.006753\n",
      "\n",
      "Epoch: [191/200]Train Loss: 0.010307  |  Test Loss: 0.007007\n",
      "\n",
      "Epoch: [192/200]Train Loss: 0.010037  |  Test Loss: 0.006740\n",
      "\n",
      "Epoch: [193/200]Train Loss: 0.009551  |  Test Loss: 0.006983\n",
      "\n",
      "Epoch: [194/200]Train Loss: 0.009769  |  Test Loss: 0.007151\n",
      "\n",
      "Epoch: [195/200]Train Loss: 0.009554  |  Test Loss: 0.006879\n",
      "\n",
      "Epoch: [196/200]Train Loss: 0.009992  |  Test Loss: 0.008537\n",
      "\n",
      "Epoch: [197/200]Train Loss: 0.009834  |  Test Loss: 0.007225\n",
      "\n",
      "Epoch: [198/200]Train Loss: 0.009658  |  Test Loss: 0.006336\n",
      "\n",
      "Epoch: [199/200]Train Loss: 0.009721  |  Test Loss: 0.007025\n",
      "\n",
      "Epoch: [200/200]Train Loss: 0.010017  |  Test Loss: 0.007198\n",
      "\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = MLPBuilder(no_features=X_train.shape[1], layers=[256, 64, 256])\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "early_stopping = EarlyStopping(patience=10, delta=0.01)\n",
    "\n",
    "# Number of epochs to train\n",
    "best_modelepochs = 200\n",
    "tr_loss, te_loss = [], []  \n",
    "\n",
    "for epoch in range(best_modelepochs):\n",
    "\n",
    "    train_loss = train_loop(train_loader, model, criterion, optimizer)\n",
    "    test_loss = test_loop(test_loader, model, criterion)\n",
    "    \n",
    "    print(f\"Epoch: [{epoch + 1:>3}/{best_modelepochs:<3}]\"\n",
    "          f\"Train Loss: {train_loss:.6f}  |  \"\n",
    "          f\"Test Loss: {test_loss:.6f}\\n\")\n",
    "\n",
    "    tr_loss.append(train_loss)\n",
    "    te_loss.append(test_loss)\n",
    "\n",
    "    # early_stopping(test_loss)\n",
    "    \n",
    "    # If early stopping is triggered, break out of the loop\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "        break\n",
    "\n",
    "\n",
    "# Change this when training a new model \n",
    "torch.save(model.state_dict(), 'models/NN_model.pth')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted X and Y coordinates (denormalized):\n",
      " [[1.112003   4.096353  ]\n",
      " [3.061477   4.0076137 ]\n",
      " [0.45731458 3.4576287 ]\n",
      " [6.7697845  1.8952261 ]\n",
      " [6.7302804  0.9021589 ]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Choose a sample input from the test set\n",
    "inputs = X_test_tensor[:5]  # Select the first 5 samples for demonstration\n",
    "\n",
    "# Perform the forward pass\n",
    "with torch.no_grad():  \n",
    "    outputs = model(inputs)\n",
    "\n",
    "# Denormalize the outputs back to the original range\n",
    "outputs_denormalized = scaler_Y.inverse_transform(outputs.numpy())\n",
    "\n",
    "# Print the model output\n",
    "print(\"Predicted X and Y coordinates (denormalized):\\n\", outputs_denormalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(1,len(tr_loss)+1),tr_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(te_loss)+1),te_loss,label='Validation Loss')\n",
    "\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Train and Test Losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
